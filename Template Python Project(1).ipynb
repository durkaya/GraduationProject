{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "\n",
    "NLTK ile Twitter üzerinde duygu analizi \n",
    "\n",
    "## Members\n",
    "\n",
    "Betül Durkaya, durkaya@itu.edu.tr\n",
    "\n",
    "## Description of the project\n",
    "\n",
    "      DUYGU ANALİZİ(SENTIMENT ANALYSIS)\n",
    "\n",
    "    Duygu analizi(sentiment analysis), fikir madenciliği(opinion mining) olarak da bilinir; insanların hizmetler, kuruluşlar, bireyler, konular, etkinlikler varlıklar ve ürünlere yönelik duygularını, fikirlerini, değerlendirmelerini ve tutumlarını analiz eden bir çalışma alanıdır. Bu büyük bir sorun alanı temsil eder. Ayrıca duygu analizi(sentiment analysis), görüş incelemesi(opinion mining), fikir çıkarımı(opinion extraction), duygu madenciliği(sentiment mining), öznel analiz(subjectivity analysis), etki analizi(affect analysis), inceleme madenciliği(rewiew mining) gibi birçok isim ve biraz farklı görevler de vardır. Ancak, şimdi hepsi duyarlılık analizi(sentiment analysis) ya da fikir madenciliği(opinion mining) çatısı altında toplanmaktadır. Endüstride iken, duygu analizi terimi daha yaygın olarak kullanılmaktadır; akademik çevrelerde hem duyarlılık analizi hem de görüş incelemesi terimi sıklıkla kullanılmaktadır.Ne olursa olsun, temelde aynı çalışma alanını temsil ediyorlar. Ancak, bazı araştırmacılar duygu analizi ve fikir madenciliğinin biraz farklı görüşleri olduğunu belirttiler. Fikir madenciliği; insanın bir varlık hakkındaki fikirlerini ayıklar ve analiz eder. Duygu analizi ise bir metinde ifade edilen duyguyu tanımlarken daha sonra bunu analiz eder. Dolayısıyla, duygu analizinin hedefi, görüşleri bulmak, ifade ettikleri duyguları belirlemek ve daha sonra kutuplarını sınıflandırmaktır. Duyarlılık analizi, çoğunlukla olumlu veya olumsuz düşünceleri ifade eden veya ima eden görüşlere odaklanır. Bir fikrin duygusal olarak hangi sınıfa girdiğini belirlemeyi amaçlar. Bu sınıflar olumlu(positive), olumsuz(negative) ve nötr(neutral) olarak adlandırılabilir.\n",
    "   \n",
    "   Dilbilimin ve doğal dil işlemenin(NLP-Natural Language Process) uzun bir geçmişi olmasına rağmen, 2000 yılından önce insanların görüş ve düşünceleri konusunda çok az araştırma yapılmıştır. O günden bu yana, alan çok aktif bir araştırma alanı haline gelmiştir. Bunun birkaç nedeni var: Birincisi, neredeyse her alanda geniş bir uygulama dizisi vardır. Duyarlılık analizini çevreleyen endüstri de ticari uygulamaların çoğalmasıyla gelişti. Bu araştırma için güçlü bir motivasyon sağlar. İkincisi, daha önce hiç araştırılmamış olan birçok zorlu araştırma problemi sunuyor. Üçüncüsü, insanlık tarihinde ilk kez, Web'deki sosyal medyada çok sayıda fikre sahip veri mevcut. Bu veriler olmadan, bir sürü araştırma mümkün olmazdı. Şaşırtıcı olmayan bir şekilde, duygu analizinin başlangıcı ve hızlı bir şekilde büyümesi, sosyal medyanın gelişimi ile çakışmaktadır. Aslında, duygu analizi şu anda sosyal medya araştırmasının merkezinde Bu nedenle, duyarlılık analizi araştırması yalnızca NLP üzerinde önemli bir etkiye sahip olmakla kalmaksızın aynı zamanda yönetim bilimleri, siyaset bilimi, ekonomi ve sosyal bilimler üzerinde de etkiler yapabilir, çünkü hepsi insanların görüşlerinden etkilenir. Duygu analizi araştırması ağırlıklı olarak 2000 yılı başından itibaren başlamış olmasına rağmen, duygu sıfatları, öznellik, bakış açısı ve etkileri üzerine daha önce yapılmış bazı çalışmalar vardır.\n",
    "\n",
    "\n",
    "Duygu Analizi Uygulamaları(Sentiment Analysis Applications)\n",
    "\n",
    "   Fikirler neredeyse tüm insan faaliyetlerinin merkezinde yer alırlar çünkü davranışlarımızın önemli etkeni bunlardır. Ne zaman bir karar vermemiz gerekse başkalarının görüşlerini bilmek isteriz. Gerçek dünyada, işletmeler ve kuruluşlar her  zaman ürün ve hizmetleri hakkında tüketici veya halkın fikirlerini bulmak istemektedir. Tüketiciler, bir ürünün satın almadan önce mevcut kullanıcılarının görüşlerini veya siyasi seçimler için bir oy vermeden önce başkalarının siyasi adaylarla ilgili görüşlerini bilmek istemektedir. Geçmişte, bir kişinin görüşe ihtiyacı olduğunda arkadaşları ve ailesine danışırdı. Bir kuruluşun veya bir işletmenin halk veya tüketici görüşlerine ihtiyacı olduğunda incelemeler ve anketler gerçekleştirirdi. Halk ve tüketici görüşlerini edinmek uzun zamandır pazarlama, halkla ilişkiler ve siyasi kampanya şirketleri için büyük bir ticari iştir. \n",
    "\n",
    "   Web'de sosyal medyanın (örneğin incelemeler, forum tartışmaları, bloglar, mikrobloglar, Twitter, yorumlar ve sosyal sitelerdeki yayınlar) büyümesiyle, bireyler ve kuruluşlar karar vermede bu medyadaki içeriği giderek kullanıyor. Günümüzde bir kişi bir ürün satın almak istiyorsa, bu kişi sadece arkadaşları ve ailesinden fikir istemekle sınırlı değildir, çünkü ürünle ilgili Web'de kamuya açık forumlarda çok sayıda kullanıcı görüşleri bulunmaktadır. Bir organizasyon açısından; halkın fikirlerini toplamak için anketler yapmak artık gerekli değildir. Çünkü böyle bir bilgi kamuya açık bir şekilde mevcuttur. Ancak, çeşitli sitelerin çoğalması yüzünden Web'deki görüş sitelerini bulma ve bunlarda yer alan bilgileri dağıtma zorlu bir görev olmayı sürdürüyor. Her site genellikle uzun bloglarda ve forum ilanlarında kolaylıkla çözülemeyen büyük bir fikir metni içeriyor. Ortalama bir okuyucu, ilgili siteleri belirlemekte ve bunlardaki fikirleri özetlemekte zorlanacaktır. Bu nedenle otomatik duyarlılık analiz sistemlerine ihtiyaç duyulmaktadır. \n",
    "\n",
    "   Son yıllarda, toplumsal ve siyasal sistemler üzerinde derin etkilere sahip olan sosyal medyada görüşlü mesajların işletmelerin ve halk duygularının yeniden şekillenmesine yardımcı olduğunu gördük. Bu tür ilanlar, 2011'de bazı Arap ülkelerinde yaşananlar gibi siyasi değişim için kitleleri harekete geçirdi. Dolayısıyla, Web üzerinde fikir toplamak ve incelemek bir zorunluluk haline geldi. Elbette, fikir verilen belgeler yalnızca Web'de varolmakla kalmaz, aynı zamanda birçok kurumda dahili veriler bulunur. Örneğin; e-postalardan ve çağrı merkezlerinden toplanan müşteri geri bildirimleri veya kuruluşlar tarafından yapılan anketlerden alınan sonuçlar. \n",
    "\n",
    "   Bu uygulamalar nedeniyle son yıllarda sanayi faaliyetleri gelişti. Duyarlılık analizi uygulamaları, tüketici ürünleri, servisler, sağlık hizmetleri ve sosyal etkinliklere finansal hizmetler ve siyasi seçimler arasında neredeyse her alana yayılmıştır. Microsoft, Google, Hewlett-Packard, SAP ve SAS gibi birçok büyük şirket, kendi kurum içi yeteneklerini inşa etmiştir. Bu pratik uygulamalar ve endüstriyel çıkarlar, duygu analizi araştırmaları için güçlü motivasyonlar sağlamıştır. Gerçek hayatta olan uygulamaların yanı sıra, birçok uygulamaya yönelik araştırma makaleleri de yayınlanmıştır.\n",
    "\n",
    "Duygu Analizi Araştırması(Sentiment Analysis Research)\n",
    "\n",
    "   Gerçek hayatta uygulamalar, duyarlılık analizinin popüler bir araştırma problemi haline gelmesinin yalnızca bir parçası. Bir NLP araştırma konusu olarak da son derece zorlayıcıdır. Ek olarak, 2000 yılından önce NLP'de veya dilbilimde çok az araştırma yapıldı. Bunun nedenlerinden biri, o zamandan beri sayısal formlarda az sayıda görüş metninin mevcut olmasıdır. 2000 yılından beri bu alan, NLP'nin en aktif araştırma alanlarından biri haline geldi. Ayrıca, veri madenciliği, Web madenciliği ve bilgi edinme konularında geniş çapta araştırılmaktadır. Aslında, bilgisayar bilimlerinden yönetim bilimlerine yayılmıştır.\n",
    "\n",
    "Analizin Farklı Seviyeleri(Different Levels of Analysis)\n",
    "\n",
    "   Product Reviews -> Sentiment Identification -> Feature Selection -> Sentiment Classification -> Sentiment Polarity\n",
    "   \n",
    "   Duygu analizi bir sınıflandırma işlemi olarak düşünülebilir. Temel olarak üç düzeyde incelenmiştir:\n",
    "\n",
    "   Doküman seviyesi(Document level):Bu seviyedeki görev, bir düşünce belgesinin olumlu veya olumsuz bir düşünceyi ifade edip etmediğini sınıflandırmaktır. Örneğin, bir ürün incelemesi göz önüne alındığında; sistem, incelemenin ürünle ilgili genel bir olumlu veya olumsuz görüş bildirip bildirmediğini belirler. Bu görev yaygın olarak belge seviyesinde(document level) duyarlılık sınıflandırması(sentiment classification) olarak bilinir. Bu analiz düzeyi, her belgenin tek bir varlık üstünde görüş bildirdiğini varsayar. Bu nedenle, birden çok varlığı değerlendiren veya karşılaştıran belgeler için geçerli değildir.\n",
    "\n",
    "   Cümle seviyesi(Sentence level):Bu seviyedeki görev, her cümlenin olumlu(positive), olumsuz(negative) veya nötr(neutral) görüşlerini ifade edip etmediğini belirler. Nötr genellikle bir görüş içermez. Bu analiz seviyesi, öznel düşünceleri ifade eden cümlelerle nesnel bilgi ifade eden cümleleri ayıran öznellik sınıflandırmasıyla(subjectivity classification) yakından ilişkilidir. Doküman seviyesinde analizden büyük bir farkı yoktur, çünkü cümlerler de kısa dokümanlardır.\n",
    "\n",
    "   Varlık ve yön düzeyi(Entity and aspect level): Hem belge düzeyi hem de cümle düzeyinde yapılan analizler tam olarak insanların ne beğendikleri ve beğenmediğini bulmazlar. Yön düzeyi daha ayrıntılı analiz yapar. Yön düzeyi daha önce özellik seviyesi olarak adlandırılmıştır. Dil yapılarına bakmak yerine, yön düzeyi doğrudan görüşe bakar. Görüş sahipleri, aynı varlıkta farklı yönlerden farklı fikirler verebilirler. Örneğin; “Although the service is not that great, I still love this restaurant.\" Cümle restaurant hakkında pozitif ancak servis hakkında negatiftir.\n",
    "   \n",
    "   Duyarlılık Sınıflandırma Teknikleri(Sentiment Classification Techniques)\n",
    "   \n",
    "   Duyarlılık Sınıflandırma teknikleri; makine öğrenme yaklaşımı(the machine learning approach), sözlüğe dayalı yaklaşım(lexicon based approach) ve hibrid yaklaşım(hybrid approach) olarak ayrılır. Makine Öğrenme Yaklaşımı, ünlü machine learning algoritmalarını uygular ve dilsel özellikleri kullanır. Sözlük tabanlı yaklaşım, bilinen ve önceden derlenmiş duygu terimlerinin bir koleksiyonu olan bir duygu sözlüğüne dayanır. Melez yaklaşım, her iki yaklaşımı birleştirir.\n",
    " \n",
    "   Machine learning ile sınıflandırma, denetimli ve denetimsiz öğrenme yöntemlerine bölünebilir. Denetlenen yöntemler, çok sayıda etiketli eğitim belgelerinden yararlanmaktadır. Bu etiketli eğitim belgelerinin bulunması güç olduğunda denetimsiz yöntemler kullanılır.\n",
    " \n",
    "   Lexicon yaklaşımı, metnin analizinde kullanılan görüş sözlüğünün bulunmasına bağlıdır. Bu yaklaşımda iki yöntem vardır: Sözlük tabanlı yaklaşım(dictionary-based approach); kök sözcüklerini bulmaya dayanır,eşanlamlılarının ve zıt anlamlılarının sözlüğünü araştırır. Korpus tabanlı yaklaşım(corpus-based approach); görüş kelimelerinin bir kök listesi ile başlar ve diğer görüş kelimelerini büyük bir korpus içerisinde bulur. Bu, istatistiksel veya semantik yöntemler kullanılarak yapılabilir.\n",
    " \n",
    "   Duygu Sözlüğü ve Sorunları(Sentiment Lexicon and Its Issues)\n",
    "\n",
    "   Şaşırtıcı olmayan bir şekilde, duyguların en önemli göstergeleri, fikir sözcükleri olarak da bilinen duygu sözcükleridir. Bunlar, pozitif veya negatif duyguları ifade etmek için sıklıkla kullanılan kelimelerdir. Örneğin; iyi, harika ve şaşırtıcı olumlu düşünce kelimeleridir ve kötü, yoksul ve korkunç olumsuz duygu sözcükleridir. Kelimelerin yanı sıra, cümle ve deyimler de vardır; duyarlılık sözcükleri ve deyimler açık nedenlerden ötürü duygu analizine aracı olur. Bu sözcük ve deyimlerin bir listesine bir duygu sözlüğü denir. Araştırmacılar, yıllar geçtikçe bu sözlükleri derlemek için çok sayıda algoritma tasarladılar. \n",
    "   \n",
    "   Duygu kelimeleri ve cümleleri duygu analizi için önemli olmasına rağmen, bunları kullanmak yeteri kadar değildir. Sorun çok daha karmaşıktır. Başka bir deyişle, duygu sözlüğünün duygu analizi için gerekli olduğu ancak yeterli olmadığı söylenebilir. Olumlu veya olumsuz bir duygu kelimesi, farklı uygulama alanlarında zıt yönlere sahip olabilir. Örneğin; \"suck\" genellikle olumsuz düşünceyi gösterir. “This camera sucks.” örneğindeki gibi. Fakat pozitif görüşte bildirebilir. Örneğin “This vacuum cleaner really sucks.”  \n",
    "\n",
    "   Twitter Üzerinde Duygu Analizi(Sentiment Analysis on Twitter)\n",
    "   \n",
    "   Sosyal medya platformları, farklı konularda düşüncelerini ifade etmek için farklı kişiler tarafından kullanılır, bu nedenle de insanların görüşlerinin değerli bir kaynağıdır. Twitter, kullanıcıların oluşturduğu çok sayıda metin mesajı içerir ve her geçen gün büyür. Twitter'ın izleyici kitleleri sıradan kullanıcılardan ünlülere, şirket temsilcilerine, siyasetçilere ve hatta ülke başkanlarına kadar değişir. Bu nedenle, farklı sosyal vgurplardan kullanıcıların metin mesajlarını toplamak mümkündür. Mesajların içeriği kişisel düşüncelerden kamuya açıklamalara kadar değişir.\n",
    "\n",
    "   Dünyanın herhangi bir yerinden veri edinebilirsiniz. Twitter'ın kitlesi birçok ülkeden kullanıcılar tarafından temsil edilmektedir. ABD'li kullanıcılar hakim olsa da, farklı dillerde veri toplamak mümkündür. \n",
    "\n",
    "   Twitter API'si iyi tasarlanmış ve kolay erişilebilirdir. Twitter verilerini analiz için uygun bir biçimdedir. Twitter'ın kullanım şartları, diğer API'lere kıyasla nispeten serbesttir. Bu özelliklerden ötürü duygu analizi için Twitter'ı kullandık.\n",
    "\n",
    "   Twitter API(Application Programming Interface)\n",
    "   \n",
    "   Uygulama Programlama Arayüzü(API), bir web tabanlı yazılım uygulamasına erişmek için kullanılan bir dizi programlama standardıdır. Twitter, Reprsentational State Transfer(REST) mimarisinin API'sini temel alır. REST mimarisi, kaynakları tanımlayan ve veriye erişim yollarını belirleyen ağ tasarım ilkelerinin bir koleksiyonunu ifade eder.\n",
    "\n",
    "\n",
    "   NLTK(NATURAL LANGUAGE TOOLKIT)\n",
    "\n",
    "NLTK(natural language toolkit), Python'da doğal dil işleme(natural language processing) için kütüphaneler ve programlar içeren bir araçtır. Başlangıçta Steven Bird, Edward Loper ve Ewan Klein tarafından geliştirilmiştir. Tokenization, ayrıştırma(parsing), sınıflandırma(classification), köklendirme(stemming), etiketleme(tagging), anlamsal akıl yürütme(semantic reasoning) için metin işleme(text processing) kütüphaneleri içerir.\n",
    "\n",
    "Referanslar(References)\n",
    "\n",
    "http://www.morganclaypool.com/doi/pdfplus/10.2200/S00416ED1V01Y201204HLT016\n",
    "http://www.sciencedirect.com/science/article/pii/S2090447914000550\n",
    "http://crowdsourcing-class.org/assignments/downloads/pak-paroubek.pdf\n",
    "https://www.irjet.net/archives/V4/i3/IRJET-V4I3581.pdf\n",
    "\n",
    "### The methods to be used\n",
    "\n",
    "Proje için Python programlama dili kullanılacak. Twittera erişim için bazı anahtarları(consumer key, consumer secret, access token ve access token secret) elde etmemiz gerekiyor, bunu Twitter API yardımıyla yapacağız. Twitter'a Python'la yazdığımız kodlarla istekte bulunacağız ve bağlantı tweepy kütüphanesi ve erişim anahtarlarımız sayesinde gerçekleşecek. Ek olarak json kütüphanesini kullanacağız, bu yüzden Twitter'dan dönen cevap json formatında olacak. Başlangıçta json datası bir txt dosyasında biriktirilecek, sonrasında datayı bir databasede saklayacağız. Bundan sonra stringleri istenen bileşenlere ayıracağız. Stringlerin birer parçası olan kelimeleri, cümlecikleri ve sembolleri \"token\" olarak isimlendrilir, ayrıca bu işleme tokenization ya da tokenizing denir. Ardından stemming ve lemmatization işlemlerini yapacağız. Stemming; sözcüğün kökünü bulmak için kelime son eklerini değiştirme ve kaldırma yöntemidir. Lemmatization ise farklılaşmış sözcük biçimlerini bir araya getirme işlemidir. Sonra, verileri NLTK ve TextBlob kullanarak analiz edeceğiz.\n",
    "\n",
    "### The data\n",
    "\n",
    "Twitter üzerinden tweetler data olarak kullanılacak ve tweetler json formatında toplanacak.\n",
    "\n",
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from processes import tokenize_process, sample_analysis\n",
    "\n",
    "\n",
    "# organizing tweet information\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    def on_connect(self):\n",
    "        print(\"Tweet streaming begin.\")\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print('Error Type: ' + status)\n",
    "        return False\n",
    "\n",
    "    def on_data(self, raw):\n",
    "        data = json.loads(raw)\n",
    "        tweet_id = data['id_str']  # The ID of tweet from Twitter in string format\n",
    "        time = data['created_at']  # The time of creation of the tweet\n",
    "        username = data['user']['screen_name']  # The Tweet author's username\n",
    "        text = data['text']  # The entire body of the Tweet\n",
    "        fs = open(\"tweets.txt\", \"a\")\n",
    "\n",
    "        try:\n",
    "            # insert tweet data to tweet.txt file if RT is not exist\n",
    "            if data['text'].find('RT @') is -1:\n",
    "                fs.write(tweet_id + '\\t' + time + '\\t' + username + '\\n' + text + '\\n\\n\\n')\n",
    "                print(tweet_id + '\\t' + time + '\\t' + username + '\\n' + text)\n",
    "                tokenize_process(tweet_id, text)    # tokenize tweets\n",
    "                sample_analysis(text)   # Analysis example\n",
    "            fs.close()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from textblob import Word, TextBlob\n",
    "\n",
    "\n",
    "def lemmatize_process(word):\n",
    "    w = Word(word)\n",
    "    w.lemmatize()\n",
    "    return w\n",
    "\n",
    "\n",
    "def stem_process(word):\n",
    "    grouping = PorterStemmer()\n",
    "    grouping.stem(word)\n",
    "\n",
    "\n",
    "def tokenize_process(tweet_id, tweet):\n",
    "    fs = open(\"tokenize.txt\", \"a\")\n",
    "    lemmatized = []\n",
    "    tokens = word_tokenize(tweet)\n",
    "    for index in range(len(tokens)):\n",
    "        lemmatized.append(lemmatize_process(tokens[index]))\n",
    "\n",
    "    fs.write('id: ' + tweet_id + '{ ')\n",
    "    fs.write(str(lemmatized))\n",
    "    fs.write(' }\\n\\n')\n",
    "    print(lemmatized)\n",
    "    fs.close()\n",
    "\n",
    "\n",
    "def sample_analysis(tweet):\n",
    "    sample = TextBlob(tweet)\n",
    "    print(sample.sentiment, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First auth done\n",
      "2nd auth done\n",
      "Tracking: ['iphone']\n",
      "Tweet streaming begin.\n",
      "853675534395609088\tSun Apr 16 18:24:42 +0000 2017\tSolisFarid\n",
      "Apple iPhone 6 Factory Unlocked 16GB Smartphone FAIR CONDITION Giveaway RT &amp; Follow https://t.co/iLLoEr1Guy\n",
      "['Apple', 'iPhone', '6', 'Factory', 'Unlocked', '16GB', 'Smartphone', 'FAIR', 'CONDITION', 'Giveaway', 'RT', '&', 'amp', ';', 'Follow', 'https', ':', '//t.co/iLLoEr1Guy']\n",
      "Sentiment(polarity=0.7, subjectivity=0.9) \n",
      "\n",
      "853675565102116864\tSun Apr 16 18:24:49 +0000 2017\tDesSays_\n",
      "Which? I have a 5 lo, https://t.co/ZY0J5rfZdR\n",
      "['Which', '?', 'I', 'have', 'a', '5', 'lo', ',', 'https', ':', '//t.co/ZY0J5rfZdR']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n",
      "853675597708611585\tSun Apr 16 18:24:57 +0000 2017\tayoo_tezz\n",
      "Check out this iPhone/iPad game I'm playing called Basketball Agent. https://t.co/D1qAQf7zFR https://t.co/S6e8Lfulhi\n",
      "['Check', 'out', 'this', 'iPhone/iPad', 'game', 'I', \"'m\", 'playing', 'called', 'Basketball', 'Agent', '.', 'https', ':', '//t.co/D1qAQf7zFR', 'https', ':', '//t.co/S6e8Lfulhi']\n",
      "Sentiment(polarity=-0.4, subjectivity=0.4) \n",
      "\n",
      "853675599793205251\tSun Apr 16 18:24:58 +0000 2017\tevanino\n",
      "LESHP VR BOX 3D VR Virtual Reality 3D Video Glasses Helmet Headset Adjust Cardboard For 4.7… https://t.co/UyVzRshneS https://t.co/EKatpbVFa8\n",
      "['LESHP', 'VR', 'BOX', '3D', 'VR', 'Virtual', 'Reality', '3D', 'Video', 'Glasses', 'Helmet', 'Headset', 'Adjust', 'Cardboard', 'For', '4.7…', 'https', ':', '//t.co/UyVzRshneS', 'https', ':', '//t.co/EKatpbVFa8']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n",
      "853675622228471808\tSun Apr 16 18:25:03 +0000 2017\tJasiah__13\n",
      "so.. apple stepped it up and you can find your airpods using find my iphone. 👌🏻\n",
      "['so..', 'apple', 'stepped', 'it', 'up', 'and', 'you', 'can', 'find', 'your', 'airpods', 'using', 'find', 'my', 'iphone', '.', '👌🏻']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n",
      "853675629795053568\tSun Apr 16 18:25:05 +0000 2017\tMyShapeStylist\n",
      "Celebrate Easter in #style\n",
      "\n",
      "With https://t.co/9IMunF7LAd\n",
      "you always ‘dress and impress’!\n",
      "\n",
      "App for iPhone/iPad\n",
      "\n",
      "#shopping #fashion #stylechat\n",
      "['Celebrate', 'Easter', 'in', '#', 'style', 'With', 'https', ':', '//t.co/9IMunF7LAd', 'you', 'always', '‘dress', 'and', 'impress’', '!', 'App', 'for', 'iPhone/iPad', '#', 'shopping', '#', 'fashion', '#', 'stylechat']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n",
      "853675634425339904\tSun Apr 16 18:25:06 +0000 2017\tDigitalMusicnew\n",
      "How one man built his own iPhone out of spare parts - BGR https://t.co/DPwJPmh4QY\n",
      "['How', 'one', 'man', 'built', 'his', 'own', 'iPhone', 'out', 'of', 'spare', 'parts', '-', 'BGR', 'https', ':', '//t.co/DPwJPmh4QY']\n",
      "Sentiment(polarity=0.6, subjectivity=1.0) \n",
      "\n",
      "853675634676998144\tSun Apr 16 18:25:06 +0000 2017\tChristmasGift88\n",
      "HOT NEW #10: Apple iPhone 5S - 16GB - AT&amp;T - Gold (Certified Refurbished) https://t.co/tetpq5pui9\n",
      "['HOT', 'NEW', '#', '10', ':', 'Apple', 'iPhone', '5S', '-', '16GB', '-', 'AT', '&', 'amp', ';', 'T', '-', 'Gold', '(', 'Certified', 'Refurbished', ')', 'https', ':', '//t.co/tetpq5pui9']\n",
      "Sentiment(polarity=0.19318181818181818, subjectivity=0.6522727272727273) \n",
      "\n",
      "853675636069675009\tSun Apr 16 18:25:06 +0000 2017\tduba_leibell\n",
      "@realDonaldTrump Hey Swamp Thing! You're a failure to launch in your first 100 days!  Keep up the great work! https://t.co/FtjvT6qOH5\n",
      "['@', 'realDonaldTrump', 'Hey', 'Swamp', 'Thing', '!', 'You', \"'re\", 'a', 'failure', 'to', 'launch', 'in', 'your', 'first', '100', 'days', '!', 'Keep', 'up', 'the', 'great', 'work', '!', 'https', ':', '//t.co/FtjvT6qOH5']\n",
      "Sentiment(polarity=0.33194444444444443, subjectivity=0.4611111111111111) \n",
      "\n",
      "853675636388372480\tSun Apr 16 18:25:06 +0000 2017\tsocial_media___\n",
      "How one man built his own iPhone out of spare parts - BGR https://t.co/fWwZ2DwNiZ\n",
      "['How', 'one', 'man', 'built', 'his', 'own', 'iPhone', 'out', 'of', 'spare', 'parts', '-', 'BGR', 'https', ':', '//t.co/fWwZ2DwNiZ']\n",
      "Sentiment(polarity=0.6, subjectivity=1.0) \n",
      "\n",
      "853675636178567168\tSun Apr 16 18:25:06 +0000 2017\tiPhoneFansclub1\n",
      "Can an iPhone survive a 100-foot fall in a chocolate bunny? - CNET https://t.co/wT6bnOhZEt\n",
      "['Can', 'an', 'iPhone', 'survive', 'a', '100-foot', 'fall', 'in', 'a', 'chocolate', 'bunny', '?', '-', 'CNET', 'https', ':', '//t.co/wT6bnOhZEt']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n",
      "853675638846349313\tSun Apr 16 18:25:07 +0000 2017\tCaseLuvr\n",
      "Custom Mixtape iPhone iPhone 5 Cover by AV_Designs https://t.co/2OlLdTLGRU via @CaseLuvr #cases #zazzle https://t.co/WGVzrVomj8\n",
      "['Custom', 'Mixtape', 'iPhone', 'iPhone', '5', 'Cover', 'by', 'AV_Designs', 'https', ':', '//t.co/2OlLdTLGRU', 'via', '@', 'CaseLuvr', '#', 'cases', '#', 'zazzle', 'https', ':', '//t.co/WGVzrVomj8']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n",
      "853675640314134528\tSun Apr 16 18:25:07 +0000 2017\tMisbulGadget\n",
      "#OnlineShop #jualan Samsung Supercopy S4,S5,Note3 dan iPhone 5s #Murah minat SMS: 085691467634 | BBM: 73F261A0\n",
      "['#', 'OnlineShop', '#', 'jualan', 'Samsung', 'Supercopy', 'S4', ',', 'S5', ',', 'Note3', 'dan', 'iPhone', '5s', '#', 'Murah', 'minat', 'SMS', ':', '085691467634', '|', 'BBM', ':', '73F261A0']\n",
      "Sentiment(polarity=0.0, subjectivity=0.0) \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-659009a913da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tracking: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#filtering keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(socks, timeout)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     sockets that can be read from immediately. \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wait_for_io_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_wait_for_io_events\u001b[0;34m(socks, events, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return [key[0].fileobj for key in\n\u001b[0;32m---> 26\u001b[0;31m                 selector.select(timeout) if key[1] & events]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    406\u001b[0m             fd_events = _syscall_wrapper(self._epoll.poll, True,\n\u001b[1;32m    407\u001b[0m                                          \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                          maxevents=max_events)\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_mask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/requests/packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36m_syscall_wrapper\u001b[0;34m(func, recalc_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_SYSCALL_SENTINEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# OSError is thrown by select.select\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# IOError is thrown by select.epoll.poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import listening\n",
    "\n",
    "#twitter api keys to authanticate\n",
    "consumer_key = \"dtKTW35ISxLtPDCszilhNk6R2\"\n",
    "consumer_secret = \"pDoisuGvzTGYte5rNEtjguiixVyys0IrL98xu5tzxE7aG8KZCJ\"\n",
    "\n",
    "access_token = \"773843946-LBFza4JmUOrzrUOkahDdtHXi6AHwFQyjwH6j7Ibg\"\n",
    "access_token_secret = \"JU0ExxNVFkQbBzipW0EOL9Lkb6dm3RadGdfoJeaLdOUgm\"\n",
    "\n",
    "#authentication sections\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "print(\"First auth done\")\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "print(\"2nd auth done\")\n",
    "\n",
    "#tracked word\n",
    "WORDS = ['iphone']\n",
    "\n",
    "#from listening library, StreamListener object created\n",
    "listener = listening.StreamListener(api=tweepy.API(wait_on_rate_limit=True))\n",
    "#from tweepy library, Stream begins\n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "\n",
    "print(\"Tracking: \" + str(WORDS))\n",
    "streamer.filter(track=WORDS, languages=[\"en\"]) #filtering keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
